{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e703e1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-16 13:59:08.867175: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2414329e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found sessions: ['NateAlexis', 'EliGianna', 'DaemahniGianna', 'SarahTexas', 'StephenMiette', 'ZahariahErin', 'ChaseGianna', 'StephenKeala', 'MarshallBritney']\n",
      "\n",
      "=== Processing Session: NateAlexis ===\n",
      "People in session: ['Alexis', 'Nate']\n",
      "  Loading data for Alexis in session NateAlexis\n",
      "    Action Units: (193, 18)\n",
      "    Hand Gestures: (104, 15)\n",
      "    Audio Features: (8318, 12)\n",
      "    Alexis final shape: (177, 27)\n",
      "    Alexis features: ['AU01', 'AU02', 'AU04', 'AU05', 'AU06', 'AU07', 'AU09', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'AU20', 'AU23', 'AU25', 'AU26', 'AU28', 'left_hand_velocity', 'right_hand_velocity', 'gesture_frequency_cumulative', 'face_touches_cumulative', 'energy_db', 'pitch_hz', 'speaking_rate']\n",
      "  Loading data for Nate in session NateAlexis\n",
      "    Action Units: (193, 18)\n",
      "    Hand Gestures: (28, 15)\n",
      "    Audio Features: (8318, 12)\n",
      "    Nate final shape: (119, 27)\n",
      "    Nate features: ['AU01', 'AU02', 'AU04', 'AU05', 'AU06', 'AU07', 'AU09', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'AU20', 'AU23', 'AU25', 'AU26', 'AU28', 'left_hand_velocity', 'right_hand_velocity', 'gesture_frequency_cumulative', 'face_touches_cumulative', 'energy_db', 'pitch_hz', 'speaking_rate']\n",
      "\n",
      "=== Processing Session: EliGianna ===\n",
      "People in session: ['Eli', 'Gianna']\n",
      "  Loading data for Eli in session EliGianna\n",
      "    Action Units: (72, 18)\n",
      "    Hand Gestures: (35, 15)\n",
      "    Audio Features: (3223, 12)\n",
      "    Eli final shape: (65, 27)\n",
      "    Eli features: ['AU01', 'AU02', 'AU04', 'AU05', 'AU06', 'AU07', 'AU09', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'AU20', 'AU23', 'AU25', 'AU26', 'AU28', 'left_hand_velocity', 'right_hand_velocity', 'gesture_frequency_cumulative', 'face_touches_cumulative', 'energy_db', 'pitch_hz', 'speaking_rate']\n",
      "  Loading data for Gianna in session EliGianna\n",
      "    Action Units: (74, 18)\n",
      "    Hand Gestures: (12, 15)\n",
      "    Audio Features: (3223, 12)\n",
      "    Gianna final shape: (65, 27)\n",
      "    Gianna features: ['AU01', 'AU02', 'AU04', 'AU05', 'AU06', 'AU07', 'AU09', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'AU20', 'AU23', 'AU25', 'AU26', 'AU28', 'left_hand_velocity', 'right_hand_velocity', 'gesture_frequency_cumulative', 'face_touches_cumulative', 'energy_db', 'pitch_hz', 'speaking_rate']\n",
      "\n",
      "=== Processing Session: DaemahniGianna ===\n",
      "People in session: ['Daemahni', 'Gianna']\n",
      "  Loading data for Daemahni in session DaemahniGianna\n",
      "    Action Units: (85, 18)\n",
      "    Hand Gestures: (253, 15)\n",
      "    Audio Features: (3656, 12)\n",
      "    Sentiment (aggregated): (83, 5)\n",
      "    Daemahni final shape: (83, 31)\n",
      "    Daemahni features: ['AU01', 'AU02', 'AU04', 'AU05', 'AU06', 'AU07', 'AU09', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'AU20', 'AU23', 'AU25', 'AU26', 'AU28', 'left_hand_velocity', 'right_hand_velocity', 'gesture_frequency_cumulative', 'face_touches_cumulative', 'energy_db', 'pitch_hz', 'speaking_rate', 'compound', 'pos', 'neu', 'neg']\n",
      "  Loading data for Gianna in session DaemahniGianna\n",
      "    Action Units: (85, 18)\n",
      "    Hand Gestures: (253, 15)\n",
      "    Audio Features: (3656, 12)\n",
      "    Sentiment (aggregated): (83, 5)\n",
      "    Gianna final shape: (83, 31)\n",
      "    Gianna features: ['AU01', 'AU02', 'AU04', 'AU05', 'AU06', 'AU07', 'AU09', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'AU20', 'AU23', 'AU25', 'AU26', 'AU28', 'left_hand_velocity', 'right_hand_velocity', 'gesture_frequency_cumulative', 'face_touches_cumulative', 'energy_db', 'pitch_hz', 'speaking_rate', 'compound', 'pos', 'neu', 'neg']\n",
      "\n",
      "=== Processing Session: SarahTexas ===\n",
      "People in session: ['Texas', 'Sarah']\n",
      "  Loading data for Texas in session SarahTexas\n",
      "    Action Units: (192, 18)\n",
      "    Hand Gestures: (86, 15)\n",
      "    Audio Features: (8261, 12)\n",
      "    Texas final shape: (168, 27)\n",
      "    Texas features: ['AU01', 'AU02', 'AU04', 'AU05', 'AU06', 'AU07', 'AU09', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'AU20', 'AU23', 'AU25', 'AU26', 'AU28', 'left_hand_velocity', 'right_hand_velocity', 'gesture_frequency_cumulative', 'face_touches_cumulative', 'energy_db', 'pitch_hz', 'speaking_rate']\n",
      "  Loading data for Sarah in session SarahTexas\n",
      "    Action Units: (192, 18)\n",
      "    Hand Gestures: (197, 15)\n",
      "    Audio Features: (8261, 12)\n",
      "    Sarah final shape: (183, 27)\n",
      "    Sarah features: ['AU01', 'AU02', 'AU04', 'AU05', 'AU06', 'AU07', 'AU09', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'AU20', 'AU23', 'AU25', 'AU26', 'AU28', 'left_hand_velocity', 'right_hand_velocity', 'gesture_frequency_cumulative', 'face_touches_cumulative', 'energy_db', 'pitch_hz', 'speaking_rate']\n",
      "\n",
      "=== Processing Session: StephenMiette ===\n",
      "People in session: ['Stephen', 'Miette']\n",
      "  Loading data for Stephen in session StephenMiette\n",
      "    Action Units: (140, 18)\n",
      "    Hand Gestures: (22, 15)\n",
      "    Audio Features: (6400, 12)\n",
      "    Stephen final shape: (108, 27)\n",
      "    Stephen features: ['AU01', 'AU02', 'AU04', 'AU05', 'AU06', 'AU07', 'AU09', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'AU20', 'AU23', 'AU25', 'AU26', 'AU28', 'left_hand_velocity', 'right_hand_velocity', 'gesture_frequency_cumulative', 'face_touches_cumulative', 'energy_db', 'pitch_hz', 'speaking_rate']\n",
      "  Loading data for Miette in session StephenMiette\n",
      "    Action Units: (146, 18)\n",
      "    Hand Gestures: (42, 15)\n",
      "    Audio Features: (6400, 12)\n",
      "    Miette final shape: (86, 27)\n",
      "    Miette features: ['AU01', 'AU02', 'AU04', 'AU05', 'AU06', 'AU07', 'AU09', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'AU20', 'AU23', 'AU25', 'AU26', 'AU28', 'left_hand_velocity', 'right_hand_velocity', 'gesture_frequency_cumulative', 'face_touches_cumulative', 'energy_db', 'pitch_hz', 'speaking_rate']\n",
      "\n",
      "=== Processing Session: ZahariahErin ===\n",
      "People in session: ['Zahariah', 'Erin']\n",
      "  Loading data for Zahariah in session ZahariahErin\n",
      "    Action Units: (151, 18)\n",
      "    Hand Gestures: (68, 15)\n",
      "    Audio Features: (6770, 12)\n",
      "    Zahariah final shape: (119, 27)\n",
      "    Zahariah features: ['AU01', 'AU02', 'AU04', 'AU05', 'AU06', 'AU07', 'AU09', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'AU20', 'AU23', 'AU25', 'AU26', 'AU28', 'left_hand_velocity', 'right_hand_velocity', 'gesture_frequency_cumulative', 'face_touches_cumulative', 'energy_db', 'pitch_hz', 'speaking_rate']\n",
      "  Loading data for Erin in session ZahariahErin\n",
      "    Action Units: (151, 18)\n",
      "    Hand Gestures: (202, 15)\n",
      "    Audio Features: (6770, 12)\n",
      "    Erin final shape: (144, 27)\n",
      "    Erin features: ['AU01', 'AU02', 'AU04', 'AU05', 'AU06', 'AU07', 'AU09', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'AU20', 'AU23', 'AU25', 'AU26', 'AU28', 'left_hand_velocity', 'right_hand_velocity', 'gesture_frequency_cumulative', 'face_touches_cumulative', 'energy_db', 'pitch_hz', 'speaking_rate']\n",
      "\n",
      "=== Processing Session: ChaseGianna ===\n",
      "People in session: ['Chase', 'Gianna']\n",
      "  Loading data for Chase in session ChaseGianna\n",
      "    Action Units: (30, 18)\n",
      "    Hand Gestures: (16, 15)\n",
      "    Audio Features: (1341, 12)\n",
      "    Chase final shape: (13, 27)\n",
      "    Chase features: ['AU01', 'AU02', 'AU04', 'AU05', 'AU06', 'AU07', 'AU09', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'AU20', 'AU23', 'AU25', 'AU26', 'AU28', 'left_hand_velocity', 'right_hand_velocity', 'gesture_frequency_cumulative', 'face_touches_cumulative', 'energy_db', 'pitch_hz', 'speaking_rate']\n",
      "  Loading data for Gianna in session ChaseGianna\n",
      "    Action Units: (30, 18)\n",
      "    Hand Gestures: (15, 15)\n",
      "    Audio Features: (1341, 12)\n",
      "    Gianna final shape: (24, 27)\n",
      "    Gianna features: ['AU01', 'AU02', 'AU04', 'AU05', 'AU06', 'AU07', 'AU09', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'AU20', 'AU23', 'AU25', 'AU26', 'AU28', 'left_hand_velocity', 'right_hand_velocity', 'gesture_frequency_cumulative', 'face_touches_cumulative', 'energy_db', 'pitch_hz', 'speaking_rate']\n",
      "\n",
      "=== Processing Session: StephenKeala ===\n",
      "People in session: ['Keala', 'Stephen']\n",
      "  Loading data for Keala in session StephenKeala\n",
      "    Action Units: (80, 18)\n",
      "    Hand Gestures: (239, 15)\n",
      "    Audio Features: (4527, 12)\n",
      "    Sentiment (aggregated): (87, 5)\n",
      "    Keala final shape: (80, 31)\n",
      "    Keala features: ['AU01', 'AU02', 'AU04', 'AU05', 'AU06', 'AU07', 'AU09', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'AU20', 'AU23', 'AU25', 'AU26', 'AU28', 'left_hand_velocity', 'right_hand_velocity', 'gesture_frequency_cumulative', 'face_touches_cumulative', 'energy_db', 'pitch_hz', 'speaking_rate', 'compound', 'pos', 'neu', 'neg']\n",
      "  Loading data for Stephen in session StephenKeala\n",
      "    Action Units: (101, 18)\n",
      "    Hand Gestures: (301, 15)\n",
      "    Audio Features: (4527, 12)\n",
      "    Sentiment (aggregated): (87, 5)\n",
      "    Stephen final shape: (88, 31)\n",
      "    Stephen features: ['AU01', 'AU02', 'AU04', 'AU05', 'AU06', 'AU07', 'AU09', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'AU20', 'AU23', 'AU25', 'AU26', 'AU28', 'left_hand_velocity', 'right_hand_velocity', 'gesture_frequency_cumulative', 'face_touches_cumulative', 'energy_db', 'pitch_hz', 'speaking_rate', 'compound', 'pos', 'neu', 'neg']\n",
      "\n",
      "=== Processing Session: MarshallBritney ===\n",
      "People in session: ['Britney', 'Marshall']\n",
      "  Loading data for Britney in session MarshallBritney\n",
      "    Action Units: (131, 18)\n",
      "    Hand Gestures: (63, 15)\n",
      "    Audio Features: (6055, 12)\n",
      "    Britney final shape: (116, 27)\n",
      "    Britney features: ['AU01', 'AU02', 'AU04', 'AU05', 'AU06', 'AU07', 'AU09', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'AU20', 'AU23', 'AU25', 'AU26', 'AU28', 'left_hand_velocity', 'right_hand_velocity', 'gesture_frequency_cumulative', 'face_touches_cumulative', 'energy_db', 'pitch_hz', 'speaking_rate']\n",
      "  Loading data for Marshall in session MarshallBritney\n",
      "    Action Units: (131, 18)\n",
      "    Hand Gestures: (17, 15)\n",
      "    Audio Features: (6055, 12)\n",
      "    Marshall final shape: (65, 27)\n",
      "    Marshall features: ['AU01', 'AU02', 'AU04', 'AU05', 'AU06', 'AU07', 'AU09', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'AU20', 'AU23', 'AU25', 'AU26', 'AU28', 'left_hand_velocity', 'right_hand_velocity', 'gesture_frequency_cumulative', 'face_touches_cumulative', 'energy_db', 'pitch_hz', 'speaking_rate']\n",
      "\n",
      "============================================================\n",
      "FINAL DATA SUMMARY\n",
      "============================================================\n",
      "NateAlexis_Alexis:\n",
      "  Shape: (177, 27)\n",
      "  Duration: 176 seconds\n",
      "  Features: 24\n",
      "\n",
      "NateAlexis_Nate:\n",
      "  Shape: (119, 27)\n",
      "  Duration: 118 seconds\n",
      "  Features: 24\n",
      "\n",
      "EliGianna_Eli:\n",
      "  Shape: (65, 27)\n",
      "  Duration: 64 seconds\n",
      "  Features: 24\n",
      "\n",
      "EliGianna_Gianna:\n",
      "  Shape: (65, 27)\n",
      "  Duration: 64 seconds\n",
      "  Features: 24\n",
      "\n",
      "DaemahniGianna_Daemahni:\n",
      "  Shape: (83, 31)\n",
      "  Duration: 82 seconds\n",
      "  Features: 28\n",
      "\n",
      "DaemahniGianna_Gianna:\n",
      "  Shape: (83, 31)\n",
      "  Duration: 82 seconds\n",
      "  Features: 28\n",
      "\n",
      "SarahTexas_Texas:\n",
      "  Shape: (168, 27)\n",
      "  Duration: 167 seconds\n",
      "  Features: 24\n",
      "\n",
      "SarahTexas_Sarah:\n",
      "  Shape: (183, 27)\n",
      "  Duration: 182 seconds\n",
      "  Features: 24\n",
      "\n",
      "StephenMiette_Stephen:\n",
      "  Shape: (108, 27)\n",
      "  Duration: 107 seconds\n",
      "  Features: 24\n",
      "\n",
      "StephenMiette_Miette:\n",
      "  Shape: (86, 27)\n",
      "  Duration: 85 seconds\n",
      "  Features: 24\n",
      "\n",
      "ZahariahErin_Zahariah:\n",
      "  Shape: (119, 27)\n",
      "  Duration: 118 seconds\n",
      "  Features: 24\n",
      "\n",
      "ZahariahErin_Erin:\n",
      "  Shape: (144, 27)\n",
      "  Duration: 143 seconds\n",
      "  Features: 24\n",
      "\n",
      "ChaseGianna_Chase:\n",
      "  Shape: (13, 27)\n",
      "  Duration: 12 seconds\n",
      "  Features: 24\n",
      "\n",
      "ChaseGianna_Gianna:\n",
      "  Shape: (24, 27)\n",
      "  Duration: 23 seconds\n",
      "  Features: 24\n",
      "\n",
      "StephenKeala_Keala:\n",
      "  Shape: (80, 31)\n",
      "  Duration: 79 seconds\n",
      "  Features: 28\n",
      "\n",
      "StephenKeala_Stephen:\n",
      "  Shape: (88, 31)\n",
      "  Duration: 87 seconds\n",
      "  Features: 28\n",
      "\n",
      "MarshallBritney_Britney:\n",
      "  Shape: (116, 27)\n",
      "  Duration: 115 seconds\n",
      "  Features: 24\n",
      "\n",
      "MarshallBritney_Marshall:\n",
      "  Shape: (65, 27)\n",
      "  Duration: 64 seconds\n",
      "  Features: 24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class FinalMultimodalDataProcessor:\n",
    "    def __init__(self, base_path=\"../DatasetCercetare\"):\n",
    "        self.base_path = base_path\n",
    "        self.sessions_data = {}\n",
    "\n",
    "    def get_all_sessions(self):\n",
    "        \"\"\"Get all unique session names from the file structure\"\"\"\n",
    "        # Get session names from AudioFeatures (since they're shared)\n",
    "        audio_files = glob.glob(f\"{self.base_path}/AudioFeatures/*.csv\")\n",
    "        sessions = [Path(file).stem for file in audio_files]\n",
    "        return sessions\n",
    "\n",
    "    def get_people_in_session(self, session_name):\n",
    "        \"\"\"Get the people involved in a session from ActionUnits files\"\"\"\n",
    "        au_files = glob.glob(f\"{self.base_path}/ActionUnits/*_on_{session_name}.csv\")\n",
    "        people = []\n",
    "        for file in au_files:\n",
    "            filename = Path(file).stem\n",
    "            person = filename.split('_on_')[0]\n",
    "            people.append(person)\n",
    "        return people\n",
    "\n",
    "    def load_person_data(self, person, session_name):\n",
    "        \"\"\"Load data for a specific person in a session\"\"\"\n",
    "        person_data = {}\n",
    "\n",
    "        print(f\"  Loading data for {person} in session {session_name}\")\n",
    "\n",
    "        # Load Action Units for this person\n",
    "        au_file = f\"{self.base_path}/ActionUnits/{person}_on_{session_name}.csv\"\n",
    "        if Path(au_file).exists():\n",
    "            au_df = pd.read_csv(au_file)\n",
    "            au_features = ['AU01', 'AU02', 'AU04', 'AU05', 'AU06', 'AU07', 'AU09',\n",
    "                          'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'AU20', 'AU23',\n",
    "                          'AU25', 'AU26', 'AU28']\n",
    "            person_data['action_units'] = au_df[['timestamp'] + au_features]\n",
    "            print(f\"    Action Units: {au_df.shape}\")\n",
    "\n",
    "        # Load Hand Gestures for this person\n",
    "        hg_file = f\"{self.base_path}/HandGestures/{person}_on_{session_name}.csv\"\n",
    "        if Path(hg_file).exists():\n",
    "            hg_df = pd.read_csv(hg_file)\n",
    "            hg_features = ['left_hand_velocity', 'right_hand_velocity',\n",
    "                          'gesture_frequency_cumulative', 'face_touches_cumulative']\n",
    "            person_data['hand_gestures'] = hg_df[['timestamp'] + hg_features]\n",
    "            print(f\"    Hand Gestures: {hg_df.shape}\")\n",
    "\n",
    "        # Load shared Audio Features (same for all people in session)\n",
    "        audio_file = f\"{self.base_path}/AudioFeatures/{session_name}.csv\"\n",
    "        if Path(audio_file).exists():\n",
    "            audio_df = pd.read_csv(audio_file)\n",
    "            audio_features = ['energy_db', 'pitch_hz', 'speaking_rate']\n",
    "            audio_df = audio_df.rename(columns={'time_seconds': 'timestamp'})\n",
    "            person_data['audio'] = audio_df[['timestamp'] + audio_features]\n",
    "            print(f\"    Audio Features: {audio_df.shape}\")\n",
    "\n",
    "        # Load shared Sentiment Analysis (filter by speaker if available)\n",
    "        sent_file = f\"{self.base_path}/SentimentAnalysis/{session_name}.csv\"\n",
    "        if Path(sent_file).exists():\n",
    "            sent_df = pd.read_csv(sent_file)\n",
    "            sent_df = sent_df.rename(columns={'second': 'timestamp'})\n",
    "\n",
    "            # Filter by speaker if the person name matches\n",
    "            if 'speaker' in sent_df.columns:\n",
    "                # Try to match person name with speaker (case insensitive)\n",
    "                person_sent = sent_df[sent_df['speaker'].str.lower() == person.lower()]\n",
    "                if len(person_sent) > 0:\n",
    "                    person_data['sentiment'] = person_sent[['timestamp', 'compound', 'pos', 'neu', 'neg']]\n",
    "                    print(f\"    Sentiment (filtered for {person}): {person_sent.shape}\")\n",
    "                else:\n",
    "                    # If no match, use aggregated sentiment for all speakers\n",
    "                    sent_agg = sent_df.groupby('timestamp').agg({\n",
    "                        'compound': 'mean', 'pos': 'mean', 'neu': 'mean', 'neg': 'mean'\n",
    "                    }).reset_index()\n",
    "                    person_data['sentiment'] = sent_agg\n",
    "                    print(f\"    Sentiment (aggregated): {sent_agg.shape}\")\n",
    "            else:\n",
    "                person_data['sentiment'] = sent_df[['timestamp', 'compound', 'pos', 'neu', 'neg']]\n",
    "                print(f\"    Sentiment: {sent_df.shape}\")\n",
    "\n",
    "        return person_data\n",
    "\n",
    "    def align_person_data(self, person_data, target_fps=1.0):\n",
    "        \"\"\"Align all modalities for a person to the same temporal grid\"\"\"\n",
    "\n",
    "        # Find common time range\n",
    "        min_time = 0\n",
    "        max_time = float('inf')\n",
    "\n",
    "        for modality, data in person_data.items():\n",
    "            if len(data) > 0:\n",
    "                min_time = max(min_time, data['timestamp'].min())\n",
    "                max_time = min(max_time, data['timestamp'].max())\n",
    "\n",
    "        # Create target timeline\n",
    "        target_timeline = np.arange(int(min_time), int(max_time) + 1)\n",
    "        aligned_data = pd.DataFrame({'timestamp': target_timeline})\n",
    "\n",
    "        # Align each modality\n",
    "        for modality, data in person_data.items():\n",
    "            if modality == 'audio':\n",
    "                # Aggregate high-frequency audio to 1-second intervals\n",
    "                audio_agg = data.groupby(data['timestamp'].round()).agg({\n",
    "                    'energy_db': 'mean',\n",
    "                    'pitch_hz': 'mean',\n",
    "                    'speaking_rate': 'mean'\n",
    "                }).reset_index()\n",
    "                aligned_data = aligned_data.merge(audio_agg, on='timestamp', how='left')\n",
    "\n",
    "            else:\n",
    "                # For other modalities, use nearest second matching\n",
    "                data_rounded = data.copy()\n",
    "                data_rounded['timestamp'] = data_rounded['timestamp'].round().astype(int)\n",
    "                data_agg = data_rounded.groupby('timestamp').first().reset_index()\n",
    "                aligned_data = aligned_data.merge(data_agg, on='timestamp', how='left')\n",
    "\n",
    "        # Fill missing values\n",
    "        aligned_data = aligned_data.fillna(method='ffill').fillna(0)\n",
    "\n",
    "        return aligned_data\n",
    "\n",
    "    def process_all_data(self):\n",
    "        \"\"\"Process all sessions and people\"\"\"\n",
    "        sessions = self.get_all_sessions()\n",
    "        print(f\"Found sessions: {sessions}\")\n",
    "\n",
    "        all_processed_data = {}\n",
    "\n",
    "        for session in sessions:\n",
    "            print(f\"\\n=== Processing Session: {session} ===\")\n",
    "            people = self.get_people_in_session(session)\n",
    "            print(f\"People in session: {people}\")\n",
    "\n",
    "            session_data = {}\n",
    "\n",
    "            for person in people:\n",
    "                # Load person's data\n",
    "                person_data = self.load_person_data(person, session)\n",
    "\n",
    "                # Align temporal data\n",
    "                aligned_data = self.align_person_data(person_data)\n",
    "\n",
    "                # Add person and session info\n",
    "                aligned_data['person'] = person\n",
    "                aligned_data['session'] = session\n",
    "\n",
    "                print(f\"    {person} final shape: {aligned_data.shape}\")\n",
    "                print(f\"    {person} features: {[col for col in aligned_data.columns if col not in ['timestamp', 'person', 'session']]}\")\n",
    "\n",
    "                session_data[person] = aligned_data\n",
    "                all_processed_data[f\"{session}_{person}\"] = aligned_data\n",
    "\n",
    "            self.sessions_data[session] = session_data\n",
    "\n",
    "        return all_processed_data\n",
    "\n",
    "# Process all data\n",
    "processor = FinalMultimodalDataProcessor()\n",
    "all_data = processor.process_all_data()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL DATA SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "for key, data in all_data.items():\n",
    "    print(f\"{key}:\")\n",
    "    print(f\"  Shape: {data.shape}\")\n",
    "    print(f\"  Duration: {data['timestamp'].max() - data['timestamp'].min():.0f} seconds\")\n",
    "    print(f\"  Features: {len([col for col in data.columns if col not in ['timestamp', 'person', 'session']])}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5419f302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth Labels:\n",
      "              session_person  is_attracted\n",
      "0          NateAlexis_Alexis             1\n",
      "1    MarshallBritney_Britney             1\n",
      "2          ChaseGianna_Chase             1\n",
      "3    DaemahniGianna_Daemahni             1\n",
      "4              EliGianna_Eli             1\n",
      "5          ZahariahErin_Erin             0\n",
      "6         ChaseGianna_Gianna             0\n",
      "7      DaemahniGianna_Gianna             1\n",
      "8           EliGianna_Gianna             0\n",
      "9         StephenKeala_Keala             0\n",
      "10  MarshallBritney_Marshall             1\n",
      "11      StephenMiette_Miette             1\n",
      "12           NateAlexis_Nate             0\n",
      "13          SarahTexas_Sarah             1\n",
      "14      StephenKeala_Stephen             0\n",
      "15     StephenMiette_Stephen             1\n",
      "16          SarahTexas_Texas             1\n",
      "17     ZahariahErin_Zahariah             1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ground_truth = {\n",
    "    'session_person': [\n",
    "        'NateAlexis_Alexis',\n",
    "        'MarshallBritney_Britney',\n",
    "        'ChaseGianna_Chase',\n",
    "        'DaemahniGianna_Daemahni',\n",
    "        'EliGianna_Eli',\n",
    "        'ZahariahErin_Erin',\n",
    "        'ChaseGianna_Gianna',\n",
    "        'DaemahniGianna_Gianna',\n",
    "        'EliGianna_Gianna',\n",
    "        'StephenKeala_Keala',\n",
    "        'MarshallBritney_Marshall',\n",
    "        'StephenMiette_Miette',\n",
    "        'NateAlexis_Nate',\n",
    "        'SarahTexas_Sarah',\n",
    "        'StephenKeala_Stephen',\n",
    "        'StephenMiette_Stephen',\n",
    "        'SarahTexas_Texas',\n",
    "        'ZahariahErin_Zahariah'\n",
    "    ],\n",
    "    'is_attracted': [\n",
    "        1,  # Alexis_on_NateAlexis\n",
    "        1,  # Britney_on_MarshallBritney\n",
    "        1,  # Chase_on_ChaseGianna\n",
    "        1,  # Daemahni_on_DaemahniGianna\n",
    "        1,  # Eli_on_EliGianna\n",
    "        0,  # Erin_on_ZahariahErin\n",
    "        0,  # Gianna_on_ChaseGianna\n",
    "        1,  # Gianna_on_DaemahniGianna\n",
    "        0,  # Gianna_on_EliGianna\n",
    "        0,  # Keala_on_StephenKeala\n",
    "        1,  # Marshall_on_MarshallBritney\n",
    "        1,  # Miette_on_StephenMiette\n",
    "        0,  # Nate_on_NateAlexis\n",
    "        1,  # Sarah_on_SarahTexas\n",
    "        0,  # Stephen_on_StephenKeala\n",
    "        1,  # Stephen_on_StephenMiette\n",
    "        1,  # Texas_on_SarahTexas\n",
    "        1   # Zahariah_on_ZahariahErin\n",
    "    ]\n",
    "}\n",
    "\n",
    "ground_truth_df = pd.DataFrame(ground_truth)\n",
    "print(\"Ground Truth Labels:\")\n",
    "print(ground_truth_df)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "085fc750",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalDataPreprocessor:\n",
    "    \"\"\"Handles data preprocessing and normalization for multimodal attraction data\"\"\"\n",
    "\n",
    "    def __init__(self, sequence_length=15):\n",
    "        self.sequence_length = sequence_length\n",
    "        self.feature_scaler = StandardScaler()\n",
    "        self.feature_names = None\n",
    "        self.is_fitted = False\n",
    "        \n",
    "        # 1. HARDCODED CANONICAL FEATURE LIST\n",
    "        self.canonical_feature_names = [\n",
    "            'AU01', 'AU02', 'AU04', 'AU05', 'AU06', 'AU07', 'AU09', 'AU10', 'AU12', 'AU14', \n",
    "            'AU15', 'AU17', 'AU20', 'AU23', 'AU25', 'AU26', 'AU28', 'left_hand_velocity', \n",
    "            'right_hand_velocity', 'gesture_frequency_cumulative', 'face_touches_cumulative', \n",
    "            'energy_db', 'pitch_hz', 'speaking_rate', 'compound', 'pos', 'neu', 'neg'\n",
    "        ]\n",
    "\n",
    "    def create_sequences(self, all_data, ground_truth_df):\n",
    "        \"\"\"Create sequences for RNN training\"\"\"\n",
    "        X_sequences = []\n",
    "        y_labels = []\n",
    "        sequence_info = []\n",
    "\n",
    "        print(\"Creating sequences...\")\n",
    "        \n",
    "        # Use the hardcoded canonical list\n",
    "        self.feature_names = self.canonical_feature_names\n",
    "        \n",
    "        # Define columns to drop for clean feature data\n",
    "        non_feature_cols = ['timestamp', 'person', 'session']\n",
    "\n",
    "\n",
    "        for key, data in all_data.items():\n",
    "            # Get label for this person\n",
    "            label_row = ground_truth_df[ground_truth_df['session_person'] == key]\n",
    "            if len(label_row) == 0:\n",
    "                continue\n",
    "\n",
    "            label = label_row['is_attracted'].iloc[0]\n",
    "\n",
    "            # Remove non-feature columns\n",
    "            # Use errors='ignore' in case some datasets don't have all non-feature columns\n",
    "            feature_data = data.drop(non_feature_cols, axis=1, errors='ignore')\n",
    "\n",
    "            # 2. ENFORCE THE CANONICAL FEATURE SET\n",
    "            # Use .reindex() to ensure all 28 columns are present.\n",
    "            # If a column is missing (like 'compound' in 24-feature data), it is added and filled with 0.0.\n",
    "            feature_data = feature_data.reindex(columns=self.feature_names, fill_value=0.0)\n",
    "            \n",
    "            # --- Sanity Check (Optional but Recommended) ---\n",
    "            # Now, every feature_data MUST have exactly len(self.feature_names) columns\n",
    "            if feature_data.shape[1] != len(self.feature_names):\n",
    "                 raise RuntimeError(f\"Feature count mismatch for {key}. Expected {len(self.feature_names)}, got {feature_data.shape[1]}\")\n",
    "            # ---------------------------------------------\n",
    "\n",
    "\n",
    "            # Create overlapping sequences\n",
    "            for i in range(len(feature_data) - self.sequence_length + 1):\n",
    "                # sequence will now consistently have shape (15, 28)\n",
    "                sequence = feature_data.iloc[i:i + self.sequence_length].values\n",
    "                X_sequences.append(sequence)\n",
    "                y_labels.append(label)\n",
    "                sequence_info.append({\n",
    "                    'person': key,\n",
    "                    'start_time': i,\n",
    "                    'end_time': i + self.sequence_length - 1\n",
    "                })\n",
    "\n",
    "        # X = np.array(X_sequences) should now successfully create a 3D array of shape (N, 15, 28)\n",
    "        X = np.array(X_sequences) \n",
    "        y = np.array(y_labels)\n",
    "\n",
    "        print(f\"Created {len(X)} sequences\")\n",
    "        print(f\"Sequence shape: {X.shape}\") # Should show (N, 15, 28)\n",
    "        print(f\"Features: {len(self.feature_names)}\")\n",
    "        print(f\"Class distribution: {np.bincount(y)}\")\n",
    "\n",
    "        return X, y, sequence_info\n",
    "        \n",
    "    def fit_normalizer(self, X_train):\n",
    "        \"\"\"Fit the feature normalizer on training data\"\"\"\n",
    "        print(\"Fitting feature normalizer...\")\n",
    "\n",
    "        # Reshape for normalization (samples*time, features)\n",
    "        X_train_reshaped = X_train.reshape(-1, X_train.shape[-1])\n",
    "\n",
    "        # Fit scaler\n",
    "        self.feature_scaler.fit(X_train_reshaped)\n",
    "        self.is_fitted = True\n",
    "\n",
    "        print(\"Feature normalizer fitted!\")\n",
    "        return self\n",
    "\n",
    "    def normalize_features(self, X):\n",
    "        \"\"\"Normalize features using fitted scaler\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Normalizer not fitted! Call fit_normalizer() first.\")\n",
    "\n",
    "        # Reshape for normalization\n",
    "        original_shape = X.shape\n",
    "        X_reshaped = X.reshape(-1, X.shape[-1])\n",
    "\n",
    "        # Transform\n",
    "        X_normalized = self.feature_scaler.transform(X_reshaped)\n",
    "        X_normalized = X_normalized.reshape(original_shape)\n",
    "\n",
    "        return X_normalized\n",
    "\n",
    "    def split_by_person(self, X, y, sequence_info, validation_split=0.2):\n",
    "        \"\"\"Split data by person to avoid data leakage\"\"\"\n",
    "        print(\"Splitting data by person...\")\n",
    "\n",
    "        # Group sequences by person\n",
    "        person_sequences = {}\n",
    "        for i, info in enumerate(sequence_info):\n",
    "            person = info['person']\n",
    "            if person not in person_sequences:\n",
    "                person_sequences[person] = []\n",
    "            person_sequences[person].append(i)\n",
    "\n",
    "        # Split by person\n",
    "        train_indices = []\n",
    "        val_indices = []\n",
    "\n",
    "        for person, indices in person_sequences.items():\n",
    "            n_val = max(1, int(len(indices) * validation_split))\n",
    "            val_indices.extend(indices[-n_val:])  # Last sequences for validation\n",
    "            train_indices.extend(indices[:-n_val])  # Rest for training\n",
    "\n",
    "        X_train = X[train_indices]\n",
    "        X_val = X[val_indices]\n",
    "        y_train = y[train_indices]\n",
    "        y_val = y[val_indices]\n",
    "\n",
    "        print(f\"Train set: {len(X_train)} sequences\")\n",
    "        print(f\"Val set: {len(X_val)} sequences\")\n",
    "        print(f\"Train class distribution: {np.bincount(y_train)}\")\n",
    "        print(f\"Val class distribution: {np.bincount(y_val)}\")\n",
    "\n",
    "        return X_train, X_val, y_train, y_val, train_indices, val_indices\n",
    "\n",
    "    def prepare_training_data(self, all_data, ground_truth_df, validation_split=0.2):\n",
    "        \"\"\"Complete data preparation pipeline\"\"\"\n",
    "        # Create sequences\n",
    "        X, y, sequence_info = self.create_sequences(all_data, ground_truth_df)\n",
    "\n",
    "        # Split by person\n",
    "        X_train, X_val, y_train, y_val, train_idx, val_idx = self.split_by_person(\n",
    "            X, y, sequence_info, validation_split\n",
    "        )\n",
    "\n",
    "        # Fit normalizer on training data\n",
    "        self.fit_normalizer(X_train)\n",
    "\n",
    "        # Normalize both sets\n",
    "        X_train_norm = self.normalize_features(X_train)\n",
    "        X_val_norm = self.normalize_features(X_val)\n",
    "\n",
    "        return {\n",
    "            'X_train': X_train_norm,\n",
    "            'X_val': X_val_norm,\n",
    "            'y_train': y_train,\n",
    "            'y_val': y_val,\n",
    "            'train_indices': train_idx,\n",
    "            'val_indices': val_idx,\n",
    "            'sequence_info': sequence_info\n",
    "        }\n",
    "\n",
    "    def preprocess_new_data(self, person_data):\n",
    "        \"\"\"Preprocess new data for prediction\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Preprocessor not fitted! Train model first.\")\n",
    "\n",
    "        # Remove non-feature columns\n",
    "        feature_data = person_data.drop(['timestamp', 'person', 'session'], axis=1, errors='ignore')\n",
    "\n",
    "        # Create sequences\n",
    "        sequences = []\n",
    "        for i in range(len(feature_data) - self.sequence_length + 1):\n",
    "            sequence = feature_data.iloc[i:i + self.sequence_length].values\n",
    "            sequences.append(sequence)\n",
    "\n",
    "        if len(sequences) == 0:\n",
    "            raise ValueError(f\"Not enough data points. Need at least {self.sequence_length} time steps.\")\n",
    "\n",
    "        X = np.array(sequences)\n",
    "        X_normalized = self.normalize_features(X)\n",
    "\n",
    "        return X_normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a97ce0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA PREPROCESSING\n",
      "============================================================\n",
      "Creating sequences...\n",
      "Created 1535 sequences\n",
      "Sequence shape: (1535, 15, 28)\n",
      "Features: 28\n",
      "Class distribution: [ 436 1099]\n",
      "Splitting data by person...\n",
      "Train set: 1235 sequences\n",
      "Val set: 300 sequences\n",
      "Train class distribution: [350 885]\n",
      "Val class distribution: [ 86 214]\n",
      "Fitting feature normalizer...\n",
      "Feature normalizer fitted!\n",
      "\n",
      "Preprocessing complete!\n",
      "Training data shape: (1235, 15, 28)\n",
      "Validation data shape: (300, 15, 28)\n",
      "Feature names: ['AU01', 'AU02', 'AU04', 'AU05', 'AU06', 'AU07', 'AU09', 'AU10', 'AU12', 'AU14', 'AU15', 'AU17', 'AU20', 'AU23', 'AU25', 'AU26', 'AU28', 'left_hand_velocity', 'right_hand_velocity', 'gesture_frequency_cumulative', 'face_touches_cumulative', 'energy_db', 'pitch_hz', 'speaking_rate', 'compound', 'pos', 'neu', 'neg']\n"
     ]
    }
   ],
   "source": [
    "# Initialize preprocessor\n",
    "print(\"=\"*60)\n",
    "print(\"DATA PREPROCESSING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "preprocessor = MultimodalDataPreprocessor(sequence_length=15)\n",
    "data_dict = preprocessor.prepare_training_data(all_data, ground_truth_df)\n",
    "\n",
    "print(f\"\\nPreprocessing complete!\")\n",
    "print(f\"Training data shape: {data_dict['X_train'].shape}\")\n",
    "print(f\"Validation data shape: {data_dict['X_val'].shape}\")\n",
    "print(f\"Feature names: {preprocessor.feature_names[:28]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "704ac0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_averaged shape: (1235, 28)\n",
      "X_val_averaged shape:  (300, 28)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_dict['X_train']  # Shape: (n_train, 15, 28)\n",
    "X_val = data_dict['X_val']      # Shape: (n_val, 15, 28)\n",
    "y_train = data_dict['y_train']\n",
    "y_val = data_dict['y_val']\n",
    "\n",
    "# Average across time dimension (axis=1) to get (n_samples, 28)\n",
    "X_train_averaged = np.mean(X_train, axis=1)  # Shape: (n_train, 28)\n",
    "X_val_averaged = np.mean(X_val, axis=1)      # Shape: (n_val, 28)\n",
    "\n",
    "print(f\"X_train_averaged shape: {X_train_averaged.shape}\")\n",
    "print(f\"X_val_averaged shape:  {X_val_averaged.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "286836c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training DataFrame:\n",
      "       AU01      AU02      AU04      AU05      AU06      AU07      AU09  \\\n",
      "0  0.832833  0.757558 -0.239359  0.540323  0.059784 -0.245942 -0.120319   \n",
      "1  0.472470  0.444433 -0.239527  0.359324  0.137621 -0.246094 -0.120320   \n",
      "2  0.666614  0.647726 -0.232520  0.581379  0.155783 -0.239736 -0.120309   \n",
      "3  0.779392  0.770140 -0.229595  0.725925  0.232981 -0.237083 -0.120307   \n",
      "4  0.953304  0.959157 -0.227899  0.949713  0.242518 -0.235544 -0.120307   \n",
      "\n",
      "       AU10      AU12      AU14  ...  right_hand_velocity  \\\n",
      "0 -0.241729  0.059784  0.059784  ...            -0.359705   \n",
      "1 -0.241862  0.137621  0.137621  ...            -0.356292   \n",
      "2 -0.236266  0.155783  0.155783  ...            -0.352879   \n",
      "3 -0.233932  0.232981  0.232981  ...            -0.349466   \n",
      "4 -0.232579  0.242518  0.242518  ...            -0.349466   \n",
      "\n",
      "   gesture_frequency_cumulative  face_touches_cumulative  energy_db  pitch_hz  \\\n",
      "0                     -0.063813                -0.435722   0.473676 -0.067573   \n",
      "1                     -0.063813                -0.435722   0.374710 -0.034781   \n",
      "2                     -0.063813                -0.435722   0.353668  0.055373   \n",
      "3                     -0.063813                -0.435722   0.178496  0.021996   \n",
      "4                     -0.063813                -0.435722   0.145474 -0.124482   \n",
      "\n",
      "   speaking_rate  compound       pos       neu       neg  \n",
      "0      -0.135277 -0.178617 -0.266911 -0.434291 -0.151274  \n",
      "1      -0.143181 -0.178617 -0.266911 -0.434291 -0.151274  \n",
      "2      -0.110238 -0.178617 -0.266911 -0.434291 -0.151274  \n",
      "3      -0.198209 -0.178617 -0.266911 -0.434291 -0.151274  \n",
      "4      -0.158862 -0.178617 -0.266911 -0.434291 -0.151274  \n",
      "\n",
      "[5 rows x 28 columns]\n",
      "\n",
      "DataFrame shape: (1235, 28)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "X_train_df = pd.DataFrame(X_train_averaged, columns=preprocessor.feature_names)\n",
    "X_val_df = pd.DataFrame(X_val_averaged, columns=preprocessor.feature_names)\n",
    "\n",
    "print(\"\\nTraining DataFrame:\")\n",
    "print(X_train_df.head())\n",
    "print(f\"\\nDataFrame shape: {X_train_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95601535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BASELINE MODEL RESULTS\n",
      "============================================================\n",
      "Baseline Accuracy:   0.7467\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Format specifier missing precision",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m=\u001b[39m\u001b[33m'\u001b[39m*\u001b[32m60\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBaseline Accuracy:   \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbaseline_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBaseline Precision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbaseline_prec\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m. 4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBaseline Recall:    \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbaseline_recall\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Format specifier missing precision"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Logistic Regression Baseline\n",
    "baseline = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "baseline.fit(X_train_averaged, y_train)\n",
    "y_pred = baseline.predict(X_val_averaged)\n",
    "\n",
    "# Calculate metrics\n",
    "baseline_acc = accuracy_score(y_val, y_pred)\n",
    "baseline_prec = precision_score(y_val, y_pred)\n",
    "baseline_recall = recall_score(y_val, y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a261216c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BASELINE MODEL RESULTS\n",
      "============================================================\n",
      "Baseline Accuracy:   0.7467\n",
      "Baseline Precision: 0.9157\n",
      "Baseline Recall:    0.7103\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*60}\")\n",
    "print(\"BASELINE MODEL RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Baseline Accuracy:   {baseline_acc:.4f}\")\n",
    "print(f\"Baseline Precision: {baseline_prec:.4f}\")\n",
    "print(f\"Baseline Recall:    {baseline_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ab714a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Not Attracted       0.54      0.84      0.65        86\n",
      "    Attracted       0.92      0.71      0.80       214\n",
      "\n",
      "     accuracy                           0.75       300\n",
      "    macro avg       0.73      0.77      0.73       300\n",
      " weighted avg       0.81      0.75      0.76       300\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 72  14]\n",
      " [ 62 152]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred, target_names=['Not Attracted', 'Attracted']))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bcd75d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
