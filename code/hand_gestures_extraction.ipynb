{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b653612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from google.colab import files\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import euclidean\n",
    "from collections import deque\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8d215ee83b4c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import os\n",
    "from google.colab import files\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import euclidean\n",
    "from collections import deque\n",
    "\n",
    "class HandGestureAnalyzer:\n",
    "    def __init__(self):\n",
    "        # Initialize MediaPipe\n",
    "        self.mp_hands = mp.solutions.hands\n",
    "        self.mp_pose = mp.solutions.pose\n",
    "        self.mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "        self.hands = self.mp_hands.Hands(\n",
    "            static_image_mode=False,\n",
    "            max_num_hands=2,\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5\n",
    "        )\n",
    "\n",
    "        self.pose = self.mp_pose.Pose(\n",
    "            static_image_mode=False,\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5\n",
    "        )\n",
    "\n",
    "        self.face_mesh = self.mp_face_mesh.FaceMesh(\n",
    "            static_image_mode=False,\n",
    "            max_num_faces=1,\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5\n",
    "        )\n",
    "\n",
    "        # Initialize tracking variables\n",
    "        self.reset_tracking()\n",
    "\n",
    "    def reset_tracking(self):\n",
    "        \"\"\"Reset all cumulative tracking variables\"\"\"\n",
    "        self.cumulative_gesture_frequency = 0\n",
    "        self.cumulative_face_touches = 0\n",
    "        self.cumulative_smoothness = 0.0\n",
    "\n",
    "        # History for smoothness calculation\n",
    "        self.hand_history = {\n",
    "            'left': deque(maxlen=5),   # Last 5 positions for smoothness\n",
    "            'right': deque(maxlen=5)\n",
    "        }\n",
    "\n",
    "        # Previous positions for velocity calculation\n",
    "        self.prev_hand_positions = {'left': None, 'right': None}\n",
    "\n",
    "        # Gesture detection state\n",
    "        self.prev_gesture_state = None\n",
    "\n",
    "        # Face region cache\n",
    "        self.face_region = None\n",
    "\n",
    "    def is_black_frame(self, frame, threshold=15):\n",
    "        mean_brightness = np.mean(frame)\n",
    "        return mean_brightness < threshold\n",
    "\n",
    "    def extract_hand_landmarks(self, frame):\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = self.hands.process(rgb_frame)\n",
    "\n",
    "        hand_landmarks = {'left': None, 'right': None}\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for idx, hand_lms in enumerate(results.multi_hand_landmarks):\n",
    "                # Get hand label (left/right)\n",
    "                if results.multi_handedness:\n",
    "                    hand_label = results.multi_handedness[idx].classification[0].label.lower()\n",
    "                else:\n",
    "                    hand_label = 'right' if idx == 0 else 'left' # Fallback\n",
    "\n",
    "                # Extract landmark coordinates\n",
    "                h, w = frame.shape[:2]\n",
    "                landmarks = []\n",
    "                for lm in hand_lms.landmark:\n",
    "                    x, y = int(lm.x * w), int(lm.y * h)\n",
    "                    landmarks.append([x, y])\n",
    "\n",
    "                hand_landmarks[hand_label] = np.array(landmarks)\n",
    "\n",
    "        return hand_landmarks\n",
    "\n",
    "    def extract_face_region(self, frame):\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = self.face_mesh.process(rgb_frame)\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            landmarks = results.multi_face_landmarks[0]\n",
    "            h, w = frame.shape[:2]\n",
    "\n",
    "            # Get face boundary points\n",
    "            face_points = []\n",
    "            for lm in landmarks.landmark:\n",
    "                x, y = int(lm.x * w), int(lm.y * h)\n",
    "                face_points.append([x, y])\n",
    "\n",
    "            face_points = np.array(face_points)\n",
    "\n",
    "            # Calculate face bounding box with margin\n",
    "            margin = 50  # pixels\n",
    "            min_x = max(0, np.min(face_points[:, 0]) - margin)\n",
    "            max_x = min(w, np.max(face_points[:, 0]) + margin)\n",
    "            min_y = max(0, np.min(face_points[:, 1]) - margin)\n",
    "            max_y = min(h, np.max(face_points[:, 1]) + margin)\n",
    "\n",
    "            return {\n",
    "                'min_x': min_x, 'max_x': max_x,\n",
    "                'min_y': min_y, 'max_y': max_y,\n",
    "                'center': [(min_x + max_x) // 2, (min_y + max_y) // 2]\n",
    "            }\n",
    "\n",
    "        return None\n",
    "\n",
    "    def calculate_hand_velocity(self, current_positions, fps):\n",
    "        velocities = {'left': 0.0, 'right': 0.0}\n",
    "\n",
    "        for hand in ['left', 'right']:\n",
    "            if (current_positions[hand] is not None and\n",
    "                self.prev_hand_positions[hand] is not None):\n",
    "\n",
    "                current_center = np.mean(current_positions[hand], axis=0)\n",
    "                prev_center = np.mean(self.prev_hand_positions[hand], axis=0)\n",
    "\n",
    "                distance = euclidean(current_center, prev_center)\n",
    "                time_delta = 1.0 / fps if fps > 0 else 1.0/30.0\n",
    "                velocity = distance / time_delta\n",
    "                velocities[hand] = velocity\n",
    "\n",
    "        self.prev_hand_positions = current_positions.copy()\n",
    "        return velocities\n",
    "\n",
    "    def detect_gesture_change(self, hand_landmarks):\n",
    "        if not any(lm is not None for lm in hand_landmarks.values()):\n",
    "            current_state = \"no_hands\"\n",
    "        else:\n",
    "            gesture_features = []\n",
    "            for hand, landmarks in hand_landmarks.items():\n",
    "                if landmarks is not None:\n",
    "                    # Fingertips indices: 4, 8, 12, 16, 20\n",
    "                    fingertips = [4, 8, 12, 16, 20]\n",
    "                    if len(landmarks) > max(fingertips):\n",
    "                        tip_distances = []\n",
    "                        for i in range(len(fingertips)-1):\n",
    "                            for j in range(i+1, len(fingertips)):\n",
    "                                dist = euclidean(landmarks[fingertips[i]], landmarks[fingertips[j]])\n",
    "                                tip_distances.append(dist)\n",
    "                        avg_tip_distance = np.mean(tip_distances) if tip_distances else 0\n",
    "                        gesture_features.append(avg_tip_distance)\n",
    "\n",
    "            if not gesture_features:\n",
    "                current_state = \"no_hands\"\n",
    "            elif np.mean(gesture_features) > 100:\n",
    "                current_state = \"open_hand\"\n",
    "            else:\n",
    "                current_state = \"closed_hand\"\n",
    "\n",
    "        gesture_changed = (self.prev_gesture_state is not None and\n",
    "                          current_state != self.prev_gesture_state)\n",
    "\n",
    "        if gesture_changed:\n",
    "            self.cumulative_gesture_frequency += 1\n",
    "\n",
    "        self.prev_gesture_state = current_state\n",
    "        return gesture_changed\n",
    "\n",
    "    def detect_face_touch(self, hand_landmarks, face_region):\n",
    "        if face_region is None:\n",
    "            return False\n",
    "\n",
    "        face_touch = False\n",
    "        for hand, landmarks in hand_landmarks.items():\n",
    "            if landmarks is not None:\n",
    "                for point in landmarks:\n",
    "                    x, y = point\n",
    "                    if (face_region['min_x'] <= x <= face_region['max_x'] and\n",
    "                        face_region['min_y'] <= y <= face_region['max_y']):\n",
    "                        face_touch = True\n",
    "                        break\n",
    "                if face_touch: break\n",
    "\n",
    "        if face_touch:\n",
    "            self.cumulative_face_touches += 1\n",
    "        return face_touch\n",
    "\n",
    "    def calculate_smoothness(self, hand_landmarks):\n",
    "        smoothness_scores = {'left': 1.0, 'right': 1.0}\n",
    "\n",
    "        for hand in ['left', 'right']:\n",
    "            if hand_landmarks[hand] is not None:\n",
    "                hand_center = np.mean(hand_landmarks[hand], axis=0)\n",
    "                self.hand_history[hand].append(hand_center)\n",
    "\n",
    "                if len(self.hand_history[hand]) >= 4:\n",
    "                    positions = list(self.hand_history[hand])\n",
    "                    velocities = []\n",
    "                    for i in range(1, len(positions)):\n",
    "                        vel = euclidean(positions[i], positions[i-1])\n",
    "                        velocities.append(vel)\n",
    "                    \n",
    "                    accelerations = []\n",
    "                    for i in range(1, len(velocities)):\n",
    "                        acc = abs(velocities[i] - velocities[i-1])\n",
    "                        accelerations.append(acc)\n",
    "\n",
    "                    if len(accelerations) >= 2:\n",
    "                        jerks = []\n",
    "                        for i in range(1, len(accelerations)):\n",
    "                            jerk = abs(accelerations[i] - accelerations[i-1])\n",
    "                            jerks.append(jerk)\n",
    "\n",
    "                        avg_jerk = np.mean(jerks)\n",
    "                        smoothness = 1.0 / (1.0 + avg_jerk / 10.0)\n",
    "                        smoothness_scores[hand] = smoothness\n",
    "\n",
    "        current_smoothness = np.mean(list(smoothness_scores.values()))\n",
    "        if self.cumulative_smoothness == 0:\n",
    "            self.cumulative_smoothness = current_smoothness\n",
    "        else:\n",
    "            self.cumulative_smoothness = 0.9 * self.cumulative_smoothness + 0.1 * current_smoothness\n",
    "\n",
    "        return smoothness_scores\n",
    "\n",
    "    def get_neutral_hand_data(self, frame_count, fps):\n",
    "        return {\n",
    "            'frame': frame_count,\n",
    "            'timestamp': frame_count / fps,\n",
    "            'left_hand_velocity': 0.0, 'right_hand_velocity': 0.0, 'avg_hand_velocity': 0.0,\n",
    "            'gesture_frequency_cumulative': self.cumulative_gesture_frequency,\n",
    "            'face_touches_cumulative': self.cumulative_face_touches,\n",
    "            'smoothness_cumulative': self.cumulative_smoothness,\n",
    "            'current_smoothness_left': 1.0, 'current_smoothness_right': 1.0,\n",
    "            'hands_detected': False, 'face_detected': False,\n",
    "            'is_black_frame': True, 'gesture_change': False, 'face_touch': False\n",
    "        }\n",
    "\n",
    "    def process_frame(self, frame, frame_count, fps):\n",
    "        if self.is_black_frame(frame):\n",
    "            return self.get_neutral_hand_data(frame_count, fps)\n",
    "\n",
    "        hand_landmarks = self.extract_hand_landmarks(frame)\n",
    "        hands_detected = any(lm is not None for lm in hand_landmarks.values())\n",
    "        \n",
    "        face_region = self.extract_face_region(frame)\n",
    "        face_detected = face_region is not None\n",
    "\n",
    "        if not hands_detected:\n",
    "            data = self.get_neutral_hand_data(frame_count, fps)\n",
    "            data['is_black_frame'] = False\n",
    "            data['face_detected'] = face_detected\n",
    "            return data\n",
    "\n",
    "        velocities = self.calculate_hand_velocity(hand_landmarks, fps)\n",
    "        avg_velocity = np.mean([v for v in velocities.values() if v > 0]) if any(velocities.values()) else 0.0\n",
    "        \n",
    "        gesture_change = self.detect_gesture_change(hand_landmarks)\n",
    "        face_touch = self.detect_face_touch(hand_landmarks, face_region)\n",
    "        smoothness_scores = self.calculate_smoothness(hand_landmarks)\n",
    "\n",
    "        return {\n",
    "            'frame': frame_count,\n",
    "            'timestamp': frame_count / fps,\n",
    "            'left_hand_velocity': velocities['left'],\n",
    "            'right_hand_velocity': velocities['right'],\n",
    "            'avg_hand_velocity': avg_velocity,\n",
    "            'gesture_frequency_cumulative': self.cumulative_gesture_frequency,\n",
    "            'face_touches_cumulative': self.cumulative_face_touches,\n",
    "            'smoothness_cumulative': self.cumulative_smoothness,\n",
    "            'current_smoothness_left': smoothness_scores['left'],\n",
    "            'current_smoothness_right': smoothness_scores['right'],\n",
    "            'hands_detected': hands_detected,\n",
    "            'face_detected': face_detected,\n",
    "            'is_black_frame': False,\n",
    "            'gesture_change': gesture_change,\n",
    "            'face_touch': face_touch\n",
    "        }\n",
    "\n",
    "def process_hand_gestures(video_path):\n",
    "    \"\"\"\n",
    "    Main function to process video and download results with dynamic filenames.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(video_path):\n",
    "        print(f\"‚ùå Error: File not found at {video_path}\")\n",
    "        return\n",
    "\n",
    "    # --- Setup Dynamic Filenames ---\n",
    "    base_name = os.path.basename(video_path)\n",
    "    file_name_only = os.path.splitext(base_name)[0]\n",
    "    \n",
    "    # Define output names based on input video name\n",
    "    # csv_complete = f\"{file_name_only}.csv\"\n",
    "    csv_hands_only = f\"{file_name_only}.csv\"\n",
    "    # csv_summary = f\"{file_name_only}_summary.csv\"\n",
    "\n",
    "    print(f\"üé¨ Processing: {base_name}\")\n",
    "    print(f\"üìÇ Main Output will be: {csv_hands_only}\")\n",
    "\n",
    "    # --- Processing Loop ---\n",
    "    analyzer = HandGestureAnalyzer()\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    results = []\n",
    "    \n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    if fps == 0 or np.isnan(fps): fps = 30.0\n",
    "    \n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Process every 10th frame\n",
    "        if frame_count % 10 == 0:\n",
    "            frame_data = analyzer.process_frame(frame, frame_count, fps)\n",
    "            results.append(frame_data)\n",
    "\n",
    "        frame_count += 1\n",
    "        if frame_count % 500 == 0:\n",
    "            print(f\"  ...processed {frame_count} frames\")\n",
    "\n",
    "    cap.release()\n",
    "    df = pd.DataFrame(results)\n",
    "\n",
    "    if len(df) == 0:\n",
    "        print(\"‚ö†Ô∏è No data extracted.\")\n",
    "        return\n",
    "\n",
    "    # --- Saving and Downloading ---\n",
    "    print(f\"\\nüíæ Saving results...\")\n",
    "\n",
    "    # 1. Complete dataset\n",
    "    # df.to_csv(csv_complete, index=False)\n",
    "    # files.download(csv_complete)\n",
    "\n",
    "    # 2. Hands-only dataset\n",
    "    hands_only_df = df[df['hands_detected'] == True].copy()\n",
    "    if len(hands_only_df) > 0:\n",
    "        hands_only_df.to_csv(csv_hands_only, index=False)\n",
    "        files.download(csv_hands_only)\n",
    "\n",
    "    print(f\"\\nAll files downloaded for {base_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229c7e426402685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Main processing function\n",
    "def process_video_hand_gestures(video_path):\n",
    "    \"\"\"Process video for hand gesture analysis\"\"\"\n",
    "\n",
    "    analyzer = HandGestureAnalyzer()\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    results = []\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_count = 0\n",
    "\n",
    "    print(\"Processing video for hand gesture analysis...\")\n",
    "    print(f\"Video: {fps:.1f} FPS, {total_frames} total frames\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Process every 10th frame for reasonable performance\n",
    "        if frame_count % 10 == 0:\n",
    "            frame_data = analyzer.process_frame(frame, frame_count, fps)\n",
    "            results.append(frame_data)\n",
    "\n",
    "        frame_count += 1\n",
    "        if frame_count % 300 == 0:  # Progress update every 300 frames\n",
    "            print(f\"Processed {frame_count}/{total_frames} frames \"\n",
    "                  f\"({frame_count/total_frames*100:.1f}%)\")\n",
    "\n",
    "    cap.release()\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af047c6d511cfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Upload and process video\n",
    "print(\"Upload your video for hand gesture analysis:\")\n",
    "# uploaded = files.upload()\n",
    "# video_path = list(uploaded.keys())[0]\n",
    "\n",
    "# Process video\n",
    "df = process_video_hand_gestures(\"/content/Stephen_on_StephenKeala.mov\")\n",
    "\n",
    "print(f\"\\nSuccessfully processed {len(df)} frames!\")\n",
    "\n",
    "# Show statistics\n",
    "hands_frames = df['hands_detected'].sum()\n",
    "face_frames = df['face_detected'].sum()\n",
    "black_frames = df['is_black_frame'].sum()\n",
    "total_gestures = df['gesture_frequency_cumulative'].iloc[-1] if len(df) > 0 else 0\n",
    "total_face_touches = df['face_touches_cumulative'].iloc[-1] if len(df) > 0 else 0\n",
    "\n",
    "print(f\"\\nAnalysis Summary:\")\n",
    "print(f\"Frames with hands detected: {hands_frames}\")\n",
    "print(f\"Frames with face detected: {face_frames}\")\n",
    "print(f\"Black frames: {black_frames}\")\n",
    "print(f\"Total gesture changes: {total_gestures}\")\n",
    "print(f\"Total face touches: {total_face_touches}\")\n",
    "print(f\"Final smoothness score: {df['smoothness_cumulative'].iloc[-1]:.3f}\" if len(df) > 0 else \"N/A\")\n",
    "\n",
    "# Show sample data\n",
    "print(f\"\\nSample hand gesture data:\")\n",
    "sample_cols = ['frame', 'timestamp', 'avg_hand_velocity', 'gesture_frequency_cumulative',\n",
    "               'face_touches_cumulative', 'smoothness_cumulative', 'hands_detected']\n",
    "print(df[sample_cols].head(10))\n",
    "\n",
    "# Create visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot 1: Hand velocities over time\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(df['timestamp'], df['left_hand_velocity'], label='Left Hand', alpha=0.7)\n",
    "ax1.plot(df['timestamp'], df['right_hand_velocity'], label='Right Hand', alpha=0.7)\n",
    "ax1.plot(df['timestamp'], df['avg_hand_velocity'], label='Average', linewidth=2)\n",
    "ax1.set_title('Hand Velocity Over Time')\n",
    "ax1.set_xlabel('Time (seconds)')\n",
    "ax1.set_ylabel('Velocity (pixels/second)')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Cumulative gesture frequency\n",
    "ax2 = axes[0, 1]\n",
    "ax2.plot(df['timestamp'], df['gesture_frequency_cumulative'], color='green', linewidth=2)\n",
    "ax2.set_title('Cumulative Gesture Changes')\n",
    "ax2.set_xlabel('Time (seconds)')\n",
    "ax2.set_ylabel('Total Gesture Changes')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Cumulative face touches\n",
    "ax3 = axes[1, 0]\n",
    "ax3.plot(df['timestamp'], df['face_touches_cumulative'], color='red', linewidth=2)\n",
    "ax3.set_title('Cumulative Face Touches')\n",
    "ax3.set_xlabel('Time (seconds)')\n",
    "ax3.set_ylabel('Total Face Touches')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Movement smoothness\n",
    "ax4 = axes[1, 1]\n",
    "ax4.plot(df['timestamp'], df['smoothness_cumulative'], color='purple', linewidth=2)\n",
    "ax4.plot(df['timestamp'], df['current_smoothness_left'], alpha=0.5, label='Left Hand Current')\n",
    "ax4.plot(df['timestamp'], df['current_smoothness_right'], alpha=0.5, label='Right Hand Current')\n",
    "ax4.set_title('Movement Smoothness')\n",
    "ax4.set_xlabel('Time (seconds)')\n",
    "ax4.set_ylabel('Smoothness Score (0-1)')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Additional analysis plots\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Velocity distribution\n",
    "plt.subplot(2, 3, 1)\n",
    "velocities = df[df['hands_detected'] == True]['avg_hand_velocity']\n",
    "plt.hist(velocities, bins=30, alpha=0.7, color='blue')\n",
    "plt.title('Hand Velocity Distribution')\n",
    "plt.xlabel('Velocity (pixels/second)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Gesture frequency rate\n",
    "plt.subplot(2, 3, 2)\n",
    "gesture_rate = df['gesture_frequency_cumulative'].diff().fillna(0)\n",
    "plt.plot(df['timestamp'], gesture_rate, color='green')\n",
    "plt.title('Gesture Change Rate')\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Gestures per frame')\n",
    "\n",
    "# Face touch events\n",
    "plt.subplot(2, 3, 3)\n",
    "touch_events = df['face_touch'].astype(int)\n",
    "plt.plot(df['timestamp'], touch_events, 'ro', markersize=3, alpha=0.7)\n",
    "plt.title('Face Touch Events')\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Touch Detected')\n",
    "\n",
    "# Hands detection timeline\n",
    "plt.subplot(2, 3, 4)\n",
    "hands_timeline = df['hands_detected'].astype(int)\n",
    "plt.plot(df['timestamp'], hands_timeline, color='orange', linewidth=2)\n",
    "plt.title('Hands Detection Timeline')\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Hands Detected')\n",
    "\n",
    "# Smoothness comparison\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.plot(df['timestamp'], df['current_smoothness_left'], label='Left Hand')\n",
    "plt.plot(df['timestamp'], df['current_smoothness_right'], label='Right Hand')\n",
    "plt.title('Per-Hand Smoothness')\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Smoothness Score')\n",
    "plt.legend()\n",
    "\n",
    "# Combined metrics\n",
    "plt.subplot(2, 3, 6)\n",
    "# Normalize metrics for comparison\n",
    "norm_velocity = df['avg_hand_velocity'] / df['avg_hand_velocity'].max() if df['avg_hand_velocity'].max() > 0 else df['avg_hand_velocity']\n",
    "norm_gestures = df['gesture_frequency_cumulative'] / df['gesture_frequency_cumulative'].max() if df['gesture_frequency_cumulative'].max() > 0 else df['gesture_frequency_cumulative']\n",
    "norm_touches = df['face_touches_cumulative'] / df['face_touches_cumulative'].max() if df['face_touches_cumulative'].max() > 0 else df['face_touches_cumulative']\n",
    "\n",
    "plt.plot(df['timestamp'], norm_velocity, label='Velocity (norm)', alpha=0.7)\n",
    "plt.plot(df['timestamp'], norm_gestures, label='Gestures (norm)', alpha=0.7)\n",
    "plt.plot(df['timestamp'], norm_touches, label='Touches (norm)', alpha=0.7)\n",
    "plt.plot(df['timestamp'], df['smoothness_cumulative'], label='Smoothness', alpha=0.7)\n",
    "plt.title('Normalized Metrics Comparison')\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Normalized Value (0-1)')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save results\n",
    "print(f\"\\nSaving results...\")\n",
    "\n",
    "# Complete dataset\n",
    "df.to_csv('hand_gesture_analysis_complete.csv', index=False)\n",
    "files.download('hand_gesture_analysis_complete.csv')\n",
    "\n",
    "# Hands-only dataset\n",
    "hands_only_df = df[df['hands_detected'] == True].copy()\n",
    "if len(hands_only_df) > 0:\n",
    "    hands_only_df.to_csv('hand_gesture_analysis_hands_only.csv', index=False)\n",
    "    files.download('hand_gesture_analysis_hands_only.csv')\n",
    "    print(f\"Hands-only dataset: {len(hands_only_df)} frames\")\n",
    "\n",
    "# Summary statistics\n",
    "summary_stats = {\n",
    "    'total_frames_processed': len(df),\n",
    "    'frames_with_hands': hands_frames,\n",
    "    'frames_with_face': face_frames,\n",
    "    'black_frames': black_frames,\n",
    "    'total_gesture_changes': total_gestures,\n",
    "    'total_face_touches': total_face_touches,\n",
    "    'final_smoothness_score': df['smoothness_cumulative'].iloc[-1] if len(df) > 0 else 0,\n",
    "    'avg_hand_velocity': df[df['hands_detected'] == True]['avg_hand_velocity'].mean() if hands_frames > 0 else 0,\n",
    "    'max_hand_velocity': df['avg_hand_velocity'].max(),\n",
    "    'video_duration_seconds': df['timestamp'].max() if len(df) > 0 else 0\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame([summary_stats])\n",
    "summary_df.to_csv('hand_gesture_summary.csv', index=False)\n",
    "files.download('hand_gesture_summary.csv')\n",
    "\n",
    "print(\"Hand gesture analysis complete!\")\n",
    "print(\"\\nFiles downloaded:\")\n",
    "print(\"  1. hand_gesture_analysis_complete.csv - All frames with hand data\")\n",
    "print(\"  2. hand_gesture_analysis_hands_only.csv - Only frames with detected hands\")\n",
    "print(\"  3. hand_gesture_summary.csv - Summary statistics\")\n",
    "\n",
    "print(f\"\\nFinal Results:\")\n",
    "print(f\"  ‚Ä¢ Average hand velocity: {summary_stats['avg_hand_velocity']:.1f} pixels/second\")\n",
    "print(f\"  ‚Ä¢ Total gesture changes: {summary_stats['total_gesture_changes']}\")\n",
    "print(f\"  ‚Ä¢ Total face touches: {summary_stats['total_face_touches']}\")\n",
    "print(f\"  ‚Ä¢ Final smoothness score: {summary_stats['final_smoothness_score']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bf0295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def process_all_videos_in_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Finds all .mov files in the folder and applies process_hand_gestures to them.\n",
    "    \"\"\"\n",
    "    # Verify folder exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"‚ùå Error: Folder not found at {folder_path}\")\n",
    "        return\n",
    "\n",
    "    # Get list of all files\n",
    "    all_files = os.listdir(folder_path)\n",
    "    \n",
    "    # Filter for .mov files (case insensitive)\n",
    "    mov_files = [f for f in all_files if f.lower().endswith('.mov')]\n",
    "    \n",
    "    total_files = len(mov_files)\n",
    "    print(f\"üìÇ Found {total_files} video files in folder.\\n\")\n",
    "\n",
    "    # Loop through each file\n",
    "    for index, filename in enumerate(mov_files):\n",
    "        video_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        print(f\"--------------------------------------------------\")\n",
    "        print(f\"‚ñ∂Ô∏è [{index + 1}/{total_files}] Starting: {filename}\")\n",
    "        \n",
    "        try:\n",
    "            # Call the function you defined previously\n",
    "            process_hand_gestures(video_path)\n",
    "            print(f\"‚úÖ Completed: {filename}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Failed to process {filename}\")\n",
    "            print(f\"Error details: {e}\")\n",
    "\n",
    "    print(f\"\\nüéâ Batch processing finished!\")\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# Change this path to your folder\n",
    "target_folder = \"/content/drive/MyDrive/DatasetCercetare/VideosEdited/\"\n",
    "\n",
    "# Run the batch\n",
    "process_all_videos_in_folder(target_folder)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
