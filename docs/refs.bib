@article{kraack2023,
  author  = {Kraack, K.},
  title   = {A Multimodal Emotion Recognition System: Integrating Facial Expressions, Body Movement, Speech, and Spoken Language},
  year    = {2023},
  journal = {arXiv preprint},
  url     = {https://arxiv.org/abs/2412.17907}
}

@article{sano2023computational,
  author  = {Sano, T. and Kawabata, H.},
  title   = {A computational approach to investigating facial attractiveness factors using geometric morphometric analysis and deep learning},
  journal = {Scientific Reports},
  volume  = {13},
  number  = {1},
  pages   = {19797},
  year    = {2023},
  doi     = {10.1038/s41598-023-47084-x},
  url     = {https://doi.org/10.1038/s41598-023-47084-x}
}

@article{lebois2018,
  author  = {Lebois, L. A. M. and Wilson-Mendenhall, C. D. and Simmons, W. K. and Barrett, L. F. and Barsalou, L. W.},
  title   = {Learning situated emotions},
  journal = {Neuropsychologia},
  year    = {2018},
  volume  = {145},
  pages   = {106637},
  doi     = {10.1016/j.neuropsychologia.2018.01.008}
}

@inproceedings{hutto2014vader,
  title={VADER: A Parsimonious Rule-Based Model for Sentiment Analysis of Social Media Text},
  author={Hutto, C. J. and Gilbert, Eric},
  booktitle={Proceedings of the International AAAI Conference on Web and Social Media},
  volume={8},
  number={1},
  pages={216--225},
  year={2014},
  doi={10.1609/icwsm.v8i1.14550}
}

@article{sherstinsky2022,
  author  = {Sherstinsky, A.},
  title   = {Facial expression and body gesture emotion recognition: A systematic review on the use of visual data in affective computing},
  journal = {IEEE Transactions on Affective Computing},
  year    = {2022},
  volume  = {13},
  number  = {4},
  pages   = {1648--1670},
  doi     = {10.1109/TAFFC.2020.2986722}
}

@article{schmidt2019,
  author  = {Schmidt, R. M.},
  title   = {Recurrent Neural Networks (RNNs): A gentle Introduction and Overview},
  journal = {arXiv preprint arXiv:1912.05911},
  year    = {2019},
  url     = {https://arxiv.org/abs/1912.05911}
}

@article{ahlawat2022,
  author  = {Ahlawat, H. and Aggarwal, N. and Gupta, D.},
  title   = {Automatic Speech Recognition: A survey of deep learning techniques and approaches},
  journal = {ACM Computing Surveys},
  year    = {2022},
  volume  = {55},
  number  = {7},
  pages   = {1--34},
  doi     = {10.1145/3555803}
}

@article{williams2023,
  author  = {Williams, Megan Nicole and Apicella, Coren Lee},
  title   = {A test of multimodal communication in humans using 881 judgements of men and women's physical, vocal, and olfactory attractiveness},
  journal = {Heliyon},
  year    = {2023},
  volume  = {9},
  number  = {6},
  pages   = {e16895},
  doi     = {10.1016/j.heliyon.2023.e16895}
}

@article{chang2021,
  author  = {Chang, A. and Kragness, H. E. and Tsou, W. and Bosnyak, D. J. and Thiede, A. and Trainor, L. J.},
  title   = {Body sway predicts romantic interest in speed dating},
  journal = {Social Cognitive and Affective Neuroscience},
  year    = {2021},
  volume  = {16},
  number  = {1--2},
  pages   = {185--192},
  doi     = {10.1093/scan/nsaa093}
}

@article{french2024,
  author  = {French, J. E. and Bolton, L. J. and Meltzer, A. L.},
  title   = {Virtual speed dating: Utilizing online‐meeting platforms to study initial attraction and relationship formation},
  journal = {Personal Relationships},
  year    = {2024},
  volume  = {31},
  number  = {2},
  pages   = {420--444},
  doi     = {10.1111/pere.12548}
}

@article{schirmer2025,
  author  = {Schirmer, A. and Franz, M. and Krismann, L. and Nöring, V. and Große, M. and Mahmut, M. and Croy, I.},
  title   = {Attraction in every sense: How looks, voice, movement and scent draw us to future lovers and friends},
  journal = {British Journal of Psychology},
  year    = {2025},
  volume  = {116},
  number  = {3},
  pages   = {684--701},
  doi     = {10.1111/bjop.12787}
}

@incollection{didonato2023,
  author    = {DiDonato, Theresa and Jakubiak, Brett},
  title     = {Romantic Attraction},
  booktitle = {The Science of Romantic Relationships},
  publisher = {Cambridge University Press},
  year      = {2023},
  pages     = {123--157}
}

@article{haidet2009,
  author  = {Haidet, K. K. and Tate, J. and Divirgilio-Thomas, D. and Kolanowski, A. and Happ, M. B.},
  title   = {Methods to improve reliability of video-recorded behavioral data},
  journal = {Research in Nursing \& Health},
  year    = {2009},
  volume  = {32},
  number  = {4},
  pages   = {465--474},
  doi     = {10.1002/nur.20334}
}

@article{2017multimodalmachinelearningsurvey,
  title={Multimodal Machine Learning: A Survey and Taxonomy}, 
  author={Tadas Baltrušaitis and Chaitanya Ahuja and Louis-Philippe Morency},
  year={2017},
  eprint={1705.09406},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/1705.09406}, 
}
@article{zadeh2017tensorfusionnetworkmultimodal,
  title={Tensor Fusion Network for Multimodal Sentiment Analysis}, 
  author={Amir Zadeh and Minghai Chen and Soujanya Poria and Erik Cambria and Louis-Philippe Morency},
  year={2017},
  eprint={1707.07250},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/1707.07250}, 
}

@article{zhao2023swr,
  author    = {Zhao, Z. and Gao, T. and Wang, H. and Schuller, B. W.},
  title     = {SWRR: Feature Map Classifier Based on Sliding Window Attention and High-Response Feature Reuse for Multimodal Emotion Recognition},
  booktitle = {Proceedings of Interspeech 2023},
  year      = {2023},
  pages     = {2433--2437},
  doi       = {10.21437/Interspeech.2023-413},
  url       = {https://doi.org/10.21437/Interspeech.2023-413}
}

@article{improving_cnn_2024,
  author  = {Anonymous},
  title   = {Improving Techniques for Convolutional Neural Networks Performance},
  journal = {European Journal of Electrical Engineering and Computer Science},
  year    = {2024},
  month   = {Jan},
  volume  = {8},
  number  = {1},
  pages   = {1--16},
  doi     = {10.24018/ejece.2024.8.1.596},
  url     = {https://ejece.org/index.php/ejece/article/view/596}
}
